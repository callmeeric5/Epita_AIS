{"cells":[{"cell_type":"markdown","metadata":{"id":"fPeikwq1xZaQ"},"source":["The goal is to check that the vector result of *king - man + woman* is close to *queen* vector"]},{"cell_type":"markdown","metadata":{"id":"_LfCrTRvxoa7"},"source":["## Try with a spaCy pretrained embedding"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"762mKs9CxSdp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting en-core-web-md==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from en-core-web-md==3.7.1) (3.7.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.7)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.6)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.2)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (5.2.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.3)\n","Requirement already satisfied: jinja2 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n","Requirement already satisfied: setuptools in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.2.2)\n","Requirement already satisfied: packaging>=20.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.6.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/ericwindsor/miniconda3/envs/ml/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[33mDEPRECATION: nb-black 1.0.7 has a non-standard dependency specifier black>='19.3'; python_version >= \"3.6\". pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of nb-black or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n"]}],"source":["import spacy\n","import spacy.cli\n","from scipy import spatial\n","# we dowload a nlp english model (with a pre-trained 300-dimension embedding) \n","spacy.cli.download(\"en_core_web_md\")\n","nlp = spacy.load('en_core_web_md')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HVvKiD8zyfL_"},"source":["spaCy allows to compute directly a pre-trained 300-dimension embedding for every word\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"i2z6QyoInHBJ"},"outputs":[{"data":{"text/plain":["array([-1.1296e-01, -4.1865e+00, -1.8453e+00,  3.0781e-01,  2.4956e+00,\n","        9.6267e-01, -1.8161e+00,  4.4655e+00, -2.8210e+00,  9.7090e-01,\n","        1.3542e+01,  4.3195e-01, -5.3098e+00,  4.7098e+00,  2.9030e+00,\n","        1.5588e+00,  6.0064e+00, -3.0345e+00,  1.0626e+00, -7.7197e-01,\n","       -5.4771e+00, -9.7380e-01, -4.4345e+00,  5.8367e+00,  2.4302e+00,\n","       -3.9408e+00, -9.1862e-01, -4.9124e+00,  1.4591e+00, -7.2772e-01,\n","        3.4957e+00, -4.0077e+00, -1.8354e+00, -4.1052e+00,  4.9211e+00,\n","       -9.7053e-01,  1.9223e+00,  5.2605e+00,  1.6086e+00,  7.1328e-01,\n","       -1.2146e+00, -1.9869e+00,  8.0265e-01,  2.9298e+00,  7.2985e-01,\n","       -6.2892e-01, -1.7082e+00,  1.9893e+00,  4.7529e-01,  3.2264e+00,\n","       -3.9215e+00,  4.6556e+00,  1.3475e+00, -1.0979e+00, -3.0365e+00,\n","        1.5815e+00,  2.2835e+00, -4.0616e+00,  2.5730e+00,  4.0618e+00,\n","        9.5438e-01, -6.2563e+00,  5.6463e+00, -3.8933e+00,  4.4076e+00,\n","        2.0517e+00, -6.6906e+00, -6.9448e+00,  6.0371e+00,  9.3081e-01,\n","        1.5180e+00,  2.3974e+00, -3.8043e+00, -4.3941e+00, -3.6979e+00,\n","        2.9489e+00, -8.9735e+00,  9.5273e+00, -6.4149e-01,  2.2565e+00,\n","       -7.2062e+00, -1.0078e+00, -4.4381e+00,  2.0424e+00, -6.6736e-01,\n","        4.3500e+00, -1.6199e+00,  3.1975e+00, -1.2065e+00, -6.5684e-01,\n","        7.5759e-01, -1.6033e+00,  2.5450e+00, -5.4999e+00, -1.8909e+00,\n","       -1.2985e-02,  2.6703e+00,  5.4623e-01, -2.4504e+00, -4.4326e-01,\n","       -1.7250e+00,  9.1585e-01,  7.5243e+00, -5.8451e-01,  3.4550e+00,\n","        3.4817e+00, -4.1599e+00, -5.5125e-01,  2.7681e-02, -3.1687e+00,\n","       -4.8459e+00,  7.9108e+00, -1.7062e+00, -2.6731e+00,  9.7841e+00,\n","        3.8851e+00, -3.7930e+00, -5.2979e-01,  6.6191e-01, -9.7232e-01,\n","       -9.4692e-01, -4.4918e+00,  1.0932e+00, -4.3751e+00,  1.3182e-02,\n","       -1.0243e+01,  4.7973e+00, -8.7426e+00,  2.5479e+00,  2.3454e+00,\n","       -6.4140e+00,  7.3875e-01,  5.8565e+00, -2.5964e-01,  1.6558e+00,\n","       -3.1353e+00, -6.6752e+00,  1.0550e+00,  1.7017e+00, -3.8360e+00,\n","       -1.1980e+01, -1.3750e+00, -1.9261e+00,  3.1267e+00,  3.2874e+00,\n","       -2.8928e+00, -1.0893e+01,  4.2848e+00, -4.0890e-02, -5.9565e-01,\n","       -3.3473e-02,  1.6832e+00,  2.1454e-01,  7.2849e+00,  2.8116e+00,\n","        2.5708e+00, -3.9823e-01, -1.7257e+00, -6.1063e+00, -4.2618e+00,\n","       -3.3886e+00, -9.2663e+00,  1.7600e-01, -3.3873e-02, -3.7070e+00,\n","       -9.1995e+00, -7.1594e+00, -6.0189e-01, -7.2560e-01,  1.5342e+00,\n","        5.1083e+00,  2.4373e+00, -3.8012e+00, -2.1752e-01,  2.9503e+00,\n","       -2.5551e+00,  4.9827e-01,  8.6823e-01, -4.3449e+00, -4.3821e+00,\n","        3.4993e+00, -1.9518e+00,  2.2036e+00, -6.6526e-01,  7.1015e+00,\n","        3.6784e+00,  2.6251e-01,  1.5379e+00, -8.1950e-01,  1.1065e+00,\n","        3.3167e+00, -5.9392e+00, -4.0191e+00,  2.6496e+00,  2.3168e+00,\n","       -8.5681e-02, -3.5059e+00,  1.5915e+00, -3.1831e-01,  6.9366e+00,\n","        3.8439e+00,  9.4076e-01, -7.5424e+00,  2.7847e+00, -2.2814e+00,\n","       -4.2487e+00, -2.6604e-01,  3.7954e+00, -3.6526e+00,  4.3823e+00,\n","       -2.6506e+00,  3.5298e+00,  2.2597e+00,  6.3055e+00, -7.0194e-01,\n","        4.1565e+00,  8.2306e+00,  5.7675e-01,  4.3596e-01, -8.8400e+00,\n","       -3.0249e+00,  4.0032e+00,  2.4232e+00,  6.9885e+00, -2.5906e-01,\n","       -4.2059e+00,  1.2643e+00,  1.0110e+01,  9.7016e-01,  2.2963e+00,\n","       -1.2802e+00, -1.4447e+00, -3.4386e+00,  5.6555e+00,  3.3911e+00,\n","        6.9418e+00, -6.8705e+00, -8.1536e-01, -7.2334e+00,  3.0509e+00,\n","        8.7676e-01,  6.4216e+00, -3.1655e+00, -1.5308e+00, -1.1056e+00,\n","       -5.0426e+00,  4.6801e+00,  4.6812e+00,  4.0401e+00, -3.7289e-01,\n","        6.7437e-01, -8.6660e+00, -9.9656e+00,  2.4979e+00, -1.4783e-01,\n","       -5.6301e+00,  4.5542e+00,  4.8165e+00, -2.2055e-01,  4.5169e+00,\n","        1.7496e+00,  2.9019e-01, -1.1683e+00, -4.3981e-01,  2.3469e+00,\n","       -4.3521e-02,  6.3715e-01,  5.8259e-01, -8.5701e+00,  4.6419e+00,\n","        2.3809e+00, -1.9273e-01, -6.9772e+00,  7.6172e-01, -6.3895e-01,\n","       -3.3769e+00,  6.1265e+00, -1.9695e+00, -2.3404e+00,  6.6789e+00,\n","       -3.5265e+00, -3.3883e+00,  6.1372e+00,  4.5550e+00,  6.0957e+00,\n","       -2.2007e-01,  6.2087e-01,  2.5527e+00, -4.5590e+00, -2.8429e+00,\n","        2.0645e+00, -1.6221e+00, -2.8171e+00, -2.9680e+00,  1.3651e+00,\n","        3.6137e+00, -3.2096e-01, -1.9346e+00, -4.8738e+00,  2.5565e+00],\n","      dtype=float32)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["king = nlp.vocab['king']\n","king.vector"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"jOknO0BRzSRy"},"outputs":[{"data":{"text/plain":["(300,)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["king.vector.shape"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"KWSerK8SsYMd"},"outputs":[{"name":"stdout","output_type":"stream","text":["queen is not one of the 10 closest words at position\n"]}],"source":["# Question 1: Compute the vector \"king - man + woman\" and try to show that the result is close to the vector representation of the word \"queen\" ;\n","# a good way to do it is, for example, to find the 10 closest word (among the nlp.vocab words) from the results of \"king - man + woman\" and to show\n","# that \"queen\" is one of them (if not the best)\n","\n","# The distance we need for that is the cosine similarity, it can be define from the spatial.distance.cosine function imported from the scipy library\n","cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n","\n","# Start the exercice here\n","# Hint: use a loop on nlp.vocab (all the words defined in spaCy vocabulary) ; for each \"word\" in the vocabulary you can check if the word has an embedding vector (\"word.has_vector\"), if the word is in\n","# lower case (\"word.is_lower\") and is alphanumeric (\"word.is_alpha\"). Try to consider only the relevant words for the exercice\n","king = nlp(\"king\")\n","man = nlp(\"man\")\n","woman = nlp(\"woman\")\n","queen = king.vector - man.vector + woman.vector\n","closest_words = []\n","for word in nlp.vocab:\n","    if word.has_vector and word.is_lower and word.is_alpha:\n","        similarity = cosine_similarity(queen, word.vector)\n","        closest_words.append((word.text, similarity))\n","\n","\n","closest_words = sorted(closest_words, key=lambda x: -x[1])\n","\n","for i, (word, similarity) in enumerate(closest_words[:10]):\n","    if word == \"queen\":\n","        print(f\"'queen' is one of the 10 closest words at position {i+1}\")\n","        break\n","print('queen is not one of the 10 closest words at position')\n"]},{"cell_type":"markdown","metadata":{"id":"ZdfvSzyFxsz5"},"source":["## Try with a pretrained Word2Vec embedding model"]},{"cell_type":"markdown","metadata":{"id":"4DnQ8h8IhJO4"},"source":["**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"wkPTJ9oLv_Hv"},"outputs":[],"source":["import gensim# Load pretrained vectors from Google\n","from gensim.models import KeyedVectors"]},{"cell_type":"markdown","metadata":{"id":"Zvv6t5uyzffL"},"source":["We load the pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased embedding models (100-dimension embedding)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"9Qm9ua_Tv_P6"},"outputs":[],"source":["import gensim.downloader as api\n","word_vectors = api.load(\"glove-wiki-gigaword-100\")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Jczj7qXfv_TB"},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n"," -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n"," -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n"," -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n","  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n","  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n","  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n"," -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n"," -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n","  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n","  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n","  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n"," -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n"," -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n","  0.16483  -0.98878 ]\n"]}],"source":["king = word_vectors['king']\n","\n","print(king)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"k7vxg9DqzreT"},"outputs":[{"data":{"text/plain":["(100,)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["king.shape"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"BhVZa8Ufv_bE"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m closest_words \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_vectors:\n\u001b[0;32m---> 12\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     closest_words\u001b[38;5;241m.\u001b[39mappend((word, similarity))\n\u001b[1;32m     18\u001b[0m closest_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(closest_words, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39mx[\u001b[38;5;241m1\u001b[39m])\n","Cell \u001b[0;32mIn[35], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Question 2: This time with the GoogleNews embedding model, try to show once again that \"king - man + woman\" is close to the vector representation of the word \"queen\" ;\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Hint: There is a pre-defined function in the gensim \"word_vectors\" object (define just above) that allows to get this result quite easily\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mspatial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m king \u001b[38;5;241m=\u001b[39m word_vectors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m man \u001b[38;5;241m=\u001b[39m word_vectors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/spatial/distance.py:684\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n","File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/spatial/distance.py:634\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    632\u001b[0m     v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m-\u001b[39m vmu\n\u001b[1;32m    633\u001b[0m uv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(u \u001b[38;5;241m*\u001b[39m v, weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[0;32m--> 634\u001b[0m uu \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m vv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39msquare(v), weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[1;32m    636\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m uv \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(uu \u001b[38;5;241m*\u001b[39m vv)\n","File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/lib/function_base.py:522\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    520\u001b[0m     avg \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mmean(axis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeepdims_kw)\n\u001b[1;32m    521\u001b[0m     avg_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(avg)\n\u001b[0;32m--> 522\u001b[0m     scl \u001b[38;5;241m=\u001b[39m \u001b[43mavg_as_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mavg_as_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(weights)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Question 2: This time with the GoogleNews embedding model, try to show once again that \"king - man + woman\" is close to the vector representation of the word \"queen\" ;\n","# Hint: There is a pre-defined function in the gensim \"word_vectors\" object (define just above) that allows to get this result quite easily\n","\n","cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n","\n","king = word_vectors['king']\n","man = word_vectors['man']\n","woman = word_vectors['woman']\n","queen = king - man + woman\n","closest_words = []\n","for word in word_vectors:\n","    similarity = cosine_similarity(queen, word)\n","\n","    closest_words.append((word, similarity))\n","\n","\n","\n","closest_words = sorted(closest_words, key=lambda x: -x[1])\n","print(closest_words[:10])\n","# for i, (word, similarity) in enumerate(closest_words[:10]):\n","#     if word == \"queen\":\n","#         print(f\"'queen' is one of the 10 closest words at position {i+1}\")\n","#         break\n","# print('queen is not one of the 10 closest words at position')"]},{"cell_type":"markdown","metadata":{"id":"TQ0XN3j7i4Fk"},"source":["## Try with fastText embedding"]},{"cell_type":"markdown","metadata":{"id":"hvKq5vbXi8up"},"source":["**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUCj7-bGjc73"},"outputs":[],"source":["#Download, extract and load Fasttext word embedding model\n","!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n","!gunzip /content/cc.en.300.bin.gz\n","!pip install fasttext"]},{"cell_type":"markdown","metadata":{"id":"suVw4N4cjAXc"},"source":["Load the english fastText model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0YH4W8m-i7P6"},"outputs":[],"source":["import fasttext \n","\n","model = fasttext.load_model(\"/content/cc.en.300.bin\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNSYa7qm4gyN"},"outputs":[],"source":["model.get_word_vector(\"king\")"]},{"cell_type":"markdown","metadata":{"id":"tXHl3VkijDWQ"},"source":["It is possible to get directly the nearest neighbors of a specific word (or even n-gram)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwxBjH-YjFg1"},"outputs":[],"source":["model.get_nearest_neighbors(\"king\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPFj4l47jHx-"},"outputs":[],"source":["# Question 3: This time with the fastText embedding model, try to show once again that \"king - man + woman\" is close to the vector representation of the word \"queen\" ;\n","# Hint: There is a pre-defined function in the fastText model, 'get_analogies', that allows to get this result quite easily"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["-2.3125"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["-1.75/4+0+(-3.75/4)*2"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["-2.4375"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["-1/4 - 2.75/4 - 3/2"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["0.6875"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["11/16"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
